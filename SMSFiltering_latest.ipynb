{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM SMS FILTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates classification of SMS as SPAM or NOT SPAM using Natural Language Preprocessing and applying different classifiers. \n",
    "\n",
    "1. Natural Language Processing: It helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important. \n",
    "2. Natural language processing includes many different techniques for interpreting human language, ranging from statistical and machine learning methods to rules-based and algorithmic approaches.\n",
    "3. These underlying tasks are often used in higher-level NLP capabilities, such as:\n",
    "    1. Content categorization. A linguistic-based document summary, including search and indexing, content alerts and duplication detection.\n",
    "    2. Topic discovery and modeling. Accurately capture the meaning and themes in text collections, and apply advanced analytics to text, like optimization and forecasting.\n",
    "    3. Contextual extraction. Automatically pull structured information from text-based sources.\n",
    "    4. Sentiment analysis. Identifying the mood or subjective opinions within large amounts of text, including average sentiment and opinion mining. \n",
    "    5. Speech-to-text and text-to-speech conversion. Transforming voice commands into written text, and vice versa. \n",
    "    6. Document summarization. Automatically generating synopses of large bodies of text.\n",
    "    7. Machine translation. Automatic translation of text or speech from one language to another.    \n",
    "4. Applications of NLP:\n",
    "    1. Investigative discovery. Identify patterns and clues in emails or written reports to help detect and solve crimes.\n",
    "    2. Subject-matter expertise. Classify content into meaningful topics so you can take action and discover trends.\n",
    "    3. Social media analytics. Track awareness and sentiment about specific topics and identify key influencers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data consists of 2 atributes: \n",
    "    1. label : It has either of 2 values: ham or spam.\n",
    "    2. text : It is a string of characters containing the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('datasets/smsspamCollection/SMSSpamCollection', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[0]\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is converted to real numbers by setting ham texts as 0 and spam texts as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#y_enc = le.fit_transform(y)\n",
    "df = df.replace(['ham','spam'],[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0  Go until jurong point, crazy.. Available only ...\n",
       "1  0                      Ok lar... Joking wif u oni...\n",
       "2  1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3  0  U dun say so early hor... U c already then say...\n",
       "4  0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_text = df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "5       FreeMsg Hey there darling it's been 3 week's n...\n",
       "6       Even my brother is not like to speak with me. ...\n",
       "7       As per your request 'Melle Melle (Oru Minnamin...\n",
       "8       WINNER!! As a valued network customer you have...\n",
       "9       Had your mobile 11 months or more? U R entitle...\n",
       "10      I'm gonna be home soon and i don't want to tal...\n",
       "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12      URGENT! You have won a 1 week FREE membership ...\n",
       "13      I've been searching for the right words to tha...\n",
       "14                    I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15      XXXMobileMovieClub: To use your credit, click ...\n",
       "16                             Oh k...i'm watching here:)\n",
       "17      Eh u remember how 2 spell his name... Yes i di...\n",
       "18      Fine if thats the way u feel. Thats the way ...\n",
       "19      England v Macedonia - dont miss the goals/team...\n",
       "20              Is that seriously how you spell his name?\n",
       "21        I‘m going to try for 2 months ha ha only joking\n",
       "22      So ü pay first lar... Then when is da stock co...\n",
       "23      Aft i finish my lunch then i go str down lor. ...\n",
       "24      Ffffffffff. Alright no way I can meet up with ...\n",
       "25      Just forced myself to eat a slice. I'm really ...\n",
       "26                         Lol your always so convincing.\n",
       "27      Did you catch the bus ? Are you frying an egg ...\n",
       "28      I'm back &amp; we're packing the car now, I'll...\n",
       "29      Ahhh. Work. I vaguely remember that! What does...\n",
       "                              ...                        \n",
       "5542             Armand says get your ass over to epsilon\n",
       "5543               U still havent got urself a jacket ah?\n",
       "5544    I'm taking derek &amp; taylor to walmart, if I...\n",
       "5545        Hi its in durban are you still on this number\n",
       "5546           Ic. There are a lotta childporn cars then.\n",
       "5547    Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5548                   No, I was trying it all weekend ;V\n",
       "5549    You know, wot people wear. T shirts, jumpers, ...\n",
       "5550          Cool, what time you think you can get here?\n",
       "5551    Wen did you get so spiritual and deep. That's ...\n",
       "5552    Have a safe trip to Nigeria. Wish you happines...\n",
       "5553                          Hahaha..use your brain dear\n",
       "5554    Well keep in mind I've only got enough gas for...\n",
       "5555    Yeh. Indians was nice. Tho it did kane me off ...\n",
       "5556    Yes i have. So that's why u texted. Pshew...mi...\n",
       "5557    No. I meant the calculation is the same. That ...\n",
       "5558                               Sorry, I'll call later\n",
       "5559    if you aren't here in the next  &lt;#&gt;  hou...\n",
       "5560                    Anything lor. Juz both of us lor.\n",
       "5561    Get me out of this dump heap. My mom decided t...\n",
       "5562    Ok lor... Sony ericsson salesman... I ask shuh...\n",
       "5563                                  Ard 6 like dat lor.\n",
       "5564    Why don't you wait 'til at least wednesday to ...\n",
       "5565                                         Huh y lei...\n",
       "5566    REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: 1, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download_shell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Tool Kit(nltk) is used to preprocess the data.\n",
    "1. Normalization: Using Regex we replace common types of words with a single label such as:\n",
    "    1. Replace email addresses with 'emailaddr'\n",
    "    2. Replace URLs with 'httpaddr'\n",
    "    3. Replace money symbols with 'moneysymb'\n",
    "    4. Replace phone numbers with 'phonenumbr'\n",
    "    5. Replace numbers with 'numbr'\n",
    "2. Stop Words: Words, such as \"when\", \"had\", \"those\" or \"before\", are called stop words and are filtered out using stopwords in nltk.corpus. \n",
    "3. Stemming: Words with various suffixes such as \"distribute\", \"distributing\", \"distributor\" or \"distribution\" are replaced with just \"distribut\" via a preprocessing step called stemming. This can be done using PorterStemmer in nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = nltk.PorterStemmer()\n",
    "def preprocess_text(messy_string):\n",
    "    assert(type(messy_string) == str)\n",
    "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr', messy_string)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',\n",
    "                     cleaned)\n",
    "    cleaned = re.sub(r'£|\\$', 'moneysymb', cleaned)\n",
    "    cleaned = re.sub(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr', cleaned)\n",
    "    cleaned = re.sub(r'\\d+(\\.\\d+)?', 'numbr', cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower())\n",
    "    return ' '.join(\n",
    "        porter.stem(term) \n",
    "        for term in cleaned.split()\n",
    "        if term not in set(stop_words)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratl numbr ticket hamilton nyc httpaddr worth moneysymbnumbr call phonenumbr send messag emailaddr get ticket'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An example to show the preprocessing.\n",
    "preprocess_text( \"\"\"***** CONGRATlations **** You won 2 tIckETs to Hamilton in \n",
    "NYC http://www.hamiltonbroadway.com/J?NaIOl/event   wORtH over $500.00...CALL \n",
    "555-477-8914 or send message to: hamilton@freetix.com to get ticket !! \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pocessed raw data\n",
    "processed = raw_text.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting words to vectors using TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenization: Its a process of breaking apart the corpus into a vocabulary of unique terms. \n",
    "    Example: \"The quick brown fox\" can be tokenized as:\n",
    "    1. \"The\", \"quick\", \"brown\", \"fox\" - unigrams.\n",
    "    2. \"The quick\", \"quick brown\", \"brown fox\" - bigrams.\n",
    "    \n",
    "2. Assign each n-gram to a feature.\n",
    "3. Compute the n-gram's frequency using tf-idf statistic:\n",
    "    1. Term frequency(tf): It tallies the occurrences of each n-gram for every training example.\n",
    "    2. Inverse document frequency(idf): Some words rarely appear in the overall corpus but show up frequently in certain subsets of messages such as spam. In order to emphasize this, we'll downweight the term frequency with inverse document frequency (idf), which is calculated by logarithmically scaling the inverse of the fraction of training examples that contain a given term.\n",
    "              tf-idf(t,i) = tf(t,i) × idf(t)\n",
    "                          = tf(t,i) × log(M/mt)\n",
    "      where tf(t,i) is the term frequency for term t in the ith training example, M is the total number of training examples, and mt is the number of training examples that contain the term t.\n",
    "4. Transform a corpus of text data into a matrix of numbers with one row per training example and one column per n-gram using TfidfVectorizer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_ngrams = vectorizer.fit_transform(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 36348)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = X_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df[0], test_size=0.15, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4736, 36348)\n",
      "(836, 36348)\n",
      "(4736,)\n",
      "(836,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. XGBoost is a library for developing fast and high performance gradient boosting tree models.\n",
    "2. XGBoost achieves the best performance on a range of difficult machine learning tasks.\n",
    "3. The XGBoost library implements the gradient boosting decision tree algorithm.\n",
    "4. Gradient boosting is an approach where new models are created that predict the residuals or errors of prior models and then added together to make the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.015836\n",
      "Will train until train-error hasn't improved in 400 rounds.\n",
      "[10]\ttrain-error:0.015836\n",
      "[20]\ttrain-error:0.014358\n",
      "[30]\ttrain-error:0.01478\n",
      "[40]\ttrain-error:0.013514\n",
      "[50]\ttrain-error:0.013514\n",
      "[60]\ttrain-error:0.013514\n",
      "[70]\ttrain-error:0.013514\n",
      "[80]\ttrain-error:0.013091\n",
      "[90]\ttrain-error:0.012247\n",
      "[100]\ttrain-error:0.011613\n",
      "[110]\ttrain-error:0.011191\n",
      "[120]\ttrain-error:0.011191\n",
      "[130]\ttrain-error:0.011191\n",
      "[140]\ttrain-error:0.01098\n",
      "[150]\ttrain-error:0.010557\n",
      "[160]\ttrain-error:0.010135\n",
      "[170]\ttrain-error:0.009924\n",
      "[180]\ttrain-error:0.008868\n",
      "[190]\ttrain-error:0.008868\n",
      "[200]\ttrain-error:0.008868\n",
      "[210]\ttrain-error:0.009079\n",
      "[220]\ttrain-error:0.009079\n",
      "[230]\ttrain-error:0.008657\n",
      "[240]\ttrain-error:0.008657\n",
      "[250]\ttrain-error:0.008657\n",
      "[260]\ttrain-error:0.008235\n",
      "[270]\ttrain-error:0.008235\n",
      "[280]\ttrain-error:0.008235\n",
      "[290]\ttrain-error:0.008024\n",
      "[300]\ttrain-error:0.007812\n",
      "[310]\ttrain-error:0.007812\n",
      "[320]\ttrain-error:0.00739\n",
      "[330]\ttrain-error:0.00739\n",
      "[340]\ttrain-error:0.00739\n",
      "[350]\ttrain-error:0.007179\n",
      "[360]\ttrain-error:0.006968\n",
      "[370]\ttrain-error:0.006968\n",
      "[380]\ttrain-error:0.006968\n",
      "[390]\ttrain-error:0.006757\n",
      "[399]\ttrain-error:0.006757\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'error'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 10\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "watchlist = [(d_train, 'train')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=400, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.977272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# Predict values for test set\n",
    "d_test = xgb.DMatrix(X_test)\n",
    "p_test = bst.predict(d_test)\n",
    "\n",
    "# Apply function round() to each element in np array\n",
    "# so predictions are all either 0 or 1.\n",
    "npround = np.vectorize(round)\n",
    "p_test_ints = npround(p_test)\n",
    "\n",
    "# Error rate for test set\n",
    "accuracy = accuracy_score(y_test, p_test_ints)\n",
    "print(\"Test Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre built classifiers from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier(n_neighbors=49)\n",
    "mnb = MultinomialNB(alpha=0.2)\n",
    "dtc = DecisionTreeClassifier(min_samples_split=7, random_state=111)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=31, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = {'SVC' : svc,'KN' : knc, 'NB': mnb, 'DT': dtc, 'LR': lrc, 'RF': rfc}\n",
    "\n",
    "def train(clf, features, targets):    \n",
    "    clf.fit(features, targets)\n",
    "\n",
    "def predict(clf, features):\n",
    "    return (clf.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_scores = []\n",
    "for k,v in clfs.items():\n",
    "    train(v, X_train, y_train)\n",
    "    pred = predict(v, X_test)\n",
    "    pred_scores.append((k, [accuracy_score(y_test , pred)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.982057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KN</th>\n",
       "      <td>0.976077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.990431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.971292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.970096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.974880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score\n",
       "SVC  0.982057\n",
       "KN   0.976077\n",
       "NB   0.990431\n",
       "DT   0.971292\n",
       "LR   0.970096\n",
       "RF   0.974880"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame.from_items(pred_scores,orient='index', columns=['Score'])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAogAAAF/CAYAAADKNjiGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSWv4/IplwhO+3TpYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185bb2c8c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.plot(kind='bar', ylim=(0.85,1.0), figsize=(9,6), align='center', colormap=\"Accent\")\n",
    "plt.xticks(np.arange(6), predictions.index)\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Distribution by Classifier')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above list of classifiers, it is clear that Naive Bayes classifier gives the highest accuracy. Hence, we predict our sample test data with that classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find(p):\n",
    "    if p == 1:\n",
    "        print (\"Message is SPAM\")\n",
    "    else:\n",
    "        print (\"Message is NOT Spam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text = \"Free tones Hope you enjoyed your new content\"\n",
    "#integers = vectorizer.transform(preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model (Naive Bayes) Saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(mnb, 'best.pkl')\n",
    "print (\"Best Model (Naive Bayes) Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = joblib.load('best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1 = \"Free tones Hope you enjoyed your new content\"\n",
    "text2 = \"No. I meant the calculation is the same. That I'll call later\"\n",
    "text3 = \"Had your contract mobile 11 Mnths? Latest Motorola Now\"\n",
    "text4 = \"what are you doing?\"\n",
    "\n",
    "integers1 = vectorizer.transform([preprocess_text(text1)])\n",
    "integers2 = vectorizer.transform([preprocess_text(text2)])\n",
    "integers3 = vectorizer.transform([preprocess_text(text3)])\n",
    "integers4 = vectorizer.transform([preprocess_text(text4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message is SPAM\n",
      "Message is NOT Spam\n",
      "Message is SPAM\n",
      "Message is NOT Spam\n"
     ]
    }
   ],
   "source": [
    "p1 = best.predict(integers1)[0]\n",
    "p2 = best.predict(integers2)[0]\n",
    "p3 = best.predict(integers3)[0]\n",
    "p4 = best.predict(integers4)[0]\n",
    "\n",
    "find(p1)\n",
    "find(p2)\n",
    "find(p3)\n",
    "find(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
